{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62JKdDPyby1l",
        "outputId": "fdd2d2e7-55a0-4061-e84b-b5e5acb5f4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import os\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "import copy # Needed to save the best model state\n",
        "\n",
        "# --- 0. Setup ---\n",
        "warnings.filterwarnings('ignore')\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# --- 1a. Mount Google Drive ---\n",
        "print(\"Mounting Google Drive...\")\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 1b. Constants & Paths ---\n",
        "DRIVE_MOUNT_POINT = '/content/drive/MyDrive/'\n",
        "PROJECT_DIR = os.path.join(DRIVE_MOUNT_POINT, 'shodhAI')\n",
        "TRAIN_DATA_PATH = os.path.join(PROJECT_DIR, 'processed_data_train.npz')\n",
        "TEST_DATA_PATH = os.path.join(PROJECT_DIR, 'processed_data_test.npz')\n",
        "MODEL_SAVE_PATH = os.path.join(PROJECT_DIR, 'dl_model_weights.pth')\n",
        "# Increase epochs to allow for better convergence\n",
        "EPOCHS = 30\n",
        "print(f\"Training epochs set to: {EPOCHS}\")\n",
        "\n",
        "# --- 1c. Hyperparameter Tuning Grid ---\n",
        "# Expand the grid to try deeper networks and slower learning rates\n",
        "HYPERPARAM_GRID = [\n",
        "    {\n",
        "        'lr': 0.0005, 'batch_size': 2048,\n",
        "        'hidden_1': 256, 'hidden_2': 128, 'hidden_3': 0, 'dropout': 0.4\n",
        "    },\n",
        "    {\n",
        "        'lr': 0.001, 'batch_size': 1024,\n",
        "        'hidden_1': 512, 'hidden_2': 256, 'hidden_3': 128, 'dropout': 0.5\n",
        "    },\n",
        "    {\n",
        "        'lr': 0.0001, 'batch_size': 2048,\n",
        "        'hidden_1': 256, 'hidden_2': 128, 'hidden_3': 0, 'dropout': 0.4\n",
        "    },\n",
        "]\n",
        "print(f\"Starting hyperparameter search over {len(HYPERPARAM_GRID)} combinations...\")\n",
        "\n",
        "# --- 2. Load Processed Data ---\n",
        "print(\"Loading processed data...\")\n",
        "try:\n",
        "    with np.load(TRAIN_DATA_PATH) as data:\n",
        "        X_train_full = data['X']\n",
        "        y_train_full = data['y']\n",
        "\n",
        "    with np.load(TEST_DATA_PATH) as data:\n",
        "        X_test = data['X']\n",
        "        y_test = data['y']\n",
        "\n",
        "    # Set the input dimension for the model\n",
        "    INPUT_DIM = X_train_full.shape[1]\n",
        "    print(f\"Model Input Dimension set to: {INPUT_DIM}\")\n",
        "\n",
        "    # --- 2b. Create Train/Validation Split ---\n",
        "    X_train_tune, X_val, y_train_tune, y_val = train_test_split(\n",
        "        X_train_full, y_train_full,\n",
        "        test_size=0.2, # 20% for validation\n",
        "        random_state=42,\n",
        "        stratify=y_train_full\n",
        "    )\n",
        "\n",
        "    print(f\"Full training data shape: {X_train_full.shape}\")\n",
        "    print(f\"  > New tuning-train set shape: {X_train_tune.shape}\")\n",
        "    print(f\"  > New validation set shape: {X_val.shape}\")\n",
        "    print(f\"Test data shape: {X_test.shape}\")\n",
        "\n",
        "    # --- 2c. Calculate Class Weights ---\n",
        "    neg_count = np.sum(y_train_tune == 0)\n",
        "    pos_count = np.sum(y_train_tune == 1)\n",
        "    pos_weight = neg_count / pos_count\n",
        "    pos_weight_tensor = torch.tensor([pos_weight], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "    print(f\"Calculated pos_weight for 'Default' class: {pos_weight:.2f}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Data files not found in {PROJECT_DIR}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred loading data: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 3. Define the DL Model (MLP) ---\n",
        "# Update model to dynamically create 2 or 3 layers\n",
        "class LoanDefaultClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, hidden_dim_3, output_dim, dropout_rate):\n",
        "        super(LoanDefaultClassifier, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(input_dim, hidden_dim_1))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_rate))\n",
        "\n",
        "        layers.append(nn.Linear(hidden_dim_1, hidden_dim_2))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_rate))\n",
        "\n",
        "        # Add a third hidden layer only if hidden_dim_3 is greater than 0\n",
        "        if hidden_dim_3 > 0:\n",
        "            layers.append(nn.Linear(hidden_dim_2, hidden_dim_3))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout_rate))\n",
        "            # The final layer's input dim is now hidden_dim_3\n",
        "            layers.append(nn.Linear(hidden_dim_3, output_dim))\n",
        "        else:\n",
        "            # The final layer's input dim is hidden_dim_2\n",
        "            layers.append(nn.Linear(hidden_dim_2, output_dim))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# --- 4. Hyperparameter Tuning Loop ---\n",
        "best_val_auc = -1\n",
        "best_model_state = None\n",
        "best_params = None\n",
        "\n",
        "# Create test dataloader\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=4096, shuffle=False)\n",
        "\n",
        "# Create validation dataloader\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=4096, shuffle=False)\n",
        "\n",
        "# Create training dataloader\n",
        "X_train_tune_tensor = torch.tensor(X_train_tune, dtype=torch.float32)\n",
        "y_train_tune_tensor = torch.tensor(y_train_tune, dtype=torch.float32).view(-1, 1)\n",
        "train_tune_dataset = TensorDataset(X_train_tune_tensor, y_train_tune_tensor)\n",
        "\n",
        "for i, params in enumerate(HYPERPARAM_GRID):\n",
        "    print(f\"\\n--- Tuning Run {i+1}/{len(HYPERPARAM_GRID)} ---\")\n",
        "    print(f\"Params: {params}\")\n",
        "\n",
        "    # --- 4a. Setup model for this run ---\n",
        "    model = LoanDefaultClassifier(\n",
        "        INPUT_DIM,\n",
        "        params['hidden_1'],\n",
        "        params['hidden_2'],\n",
        "        params['hidden_3'],\n",
        "        1,\n",
        "        params['dropout']\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_tune_dataset,\n",
        "        batch_size=params['batch_size'],\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # --- 4b. Training Loop ---\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        # Use tqdm for a progress bar on the inner loop\n",
        "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Print loss just for the last epoch\n",
        "        if epoch == EPOCHS - 1:\n",
        "            avg_loss = total_loss / len(train_loader)\n",
        "            print(f\"  Epoch [{epoch+1}/{EPOCHS}], Avg Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # --- 4c. Validation Loop ---\n",
        "    model.eval()\n",
        "    val_preds_probs = []\n",
        "    val_labels_list = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(inputs)\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            val_preds_probs.extend(probs.cpu().numpy())\n",
        "            val_labels_list.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_preds_probs = np.array(val_preds_probs).flatten()\n",
        "    val_labels = np.array(val_labels_list).flatten()\n",
        "\n",
        "    try:\n",
        "        val_auc = roc_auc_score(val_labels, val_preds_probs)\n",
        "        print(f\"  Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            best_params = params\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "            print(f\"  *** New Best Model Found (AUC: {best_val_auc:.4f}) ***\")\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"  Error calculating validation AUC.\")\n",
        "\n",
        "print(\"\\n--- Hyperparameter Tuning Complete ---\")\n",
        "print(f\"Best Validation AUC: {best_val_auc:.4f}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# --- 5. Final Model Setup & Evaluation ---\n",
        "print(\"\\nLoading best model for final test set evaluation...\")\n",
        "# Instantiate the best model\n",
        "if best_params is None:\n",
        "    print(\"Error: No best model was found from tuning. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "final_model = LoanDefaultClassifier(\n",
        "    INPUT_DIM,\n",
        "    best_params['hidden_1'],\n",
        "    best_params['hidden_2'],\n",
        "    best_params['hidden_3'],\n",
        "    1,\n",
        "    best_params['dropout']\n",
        ").to(DEVICE)\n",
        "\n",
        "# Load the saved best weights\n",
        "if best_model_state is not None:\n",
        "    final_model.load_state_dict(best_model_state)\n",
        "else:\n",
        "    print(\"Error: No best model was saved. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# --- 6. Save the Final Model ---\n",
        "print(f\"Saving best model weights to {MODEL_SAVE_PATH}...\")\n",
        "torch.save(final_model.state_dict(), MODEL_SAVE_PATH)\n",
        "print(\"Model saved successfully.\")\n",
        "\n",
        "# --- 7. Final Evaluation on Test Set ---\n",
        "print(\"\\n--- Starting Final Model Evaluation on TEST SET ---\")\n",
        "final_model.eval()\n",
        "all_preds_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "        outputs = final_model(inputs)\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        all_preds_probs.extend(probs.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "all_preds_probs = np.array(all_preds_probs).flatten()\n",
        "all_labels = np.array(all_labels).flatten()\n",
        "\n",
        "# --- 8. Final Metrics Calculation ---\n",
        "try:\n",
        "    auc = roc_auc_score(all_labels, all_preds_probs)\n",
        "\n",
        "    # Find the optimal threshold\n",
        "    precisions, recalls, thresholds = precision_recall_curve(all_labels, all_preds_probs)\n",
        "    f1_scores = (2 * precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "    best_f1_idx = np.argmax(f1_scores)\n",
        "    best_threshold = thresholds[best_f1_idx]\n",
        "    best_f1 = f1_scores[best_f1_idx]\n",
        "\n",
        "    all_preds_binary_opt = (all_preds_probs >= best_threshold).astype(int)\n",
        "    precision_opt = precision_score(all_labels, all_preds_binary_opt)\n",
        "    recall_opt = recall_score(all_labels, all_preds_binary_opt)\n",
        "\n",
        "    # --- 9. Final Report ---\n",
        "    print(\"\\n--- Test Set Performance (Task 2) ---\")\n",
        "    print(f\"AUC (Area Under the ROC Curve): {auc:.4f}\")\n",
        "    print(\"-----------------------------------------\")\n",
        "    print(f\"Optimal Threshold (for max F1): {best_threshold:.4f}\")\n",
        "    print(\"Metrics at optimal threshold:\")\n",
        "    print(f\"  Best F1-Score:                  {best_f1:.4f}\")\n",
        "    print(f\"  Precision (at best F1):         {precision_opt:.4f}\")\n",
        "    print(f\"  Recall (at best F1):            {recall_opt:.4f}\")\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Error calculating metrics: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during final evaluation: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Task 2 Complete ---\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71L_RpGue7No",
        "outputId": "6f7e65de-6f9f-4807-977e-9df0d5aaa710"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Training epochs set to: 30\n",
            "Starting hyperparameter search over 3 combinations...\n",
            "Loading processed data...\n",
            "Model Input Dimension set to: 33\n",
            "Full training data shape: (140866, 33)\n",
            "  > New tuning-train set shape: (112692, 33)\n",
            "  > New validation set shape: (28174, 33)\n",
            "Test data shape: (35217, 33)\n",
            "Calculated pos_weight for 'Default' class: 4.02\n",
            "\n",
            "--- Tuning Run 1/3 ---\n",
            "Params: {'lr': 0.0005, 'batch_size': 2048, 'hidden_1': 256, 'hidden_2': 128, 'hidden_3': 0, 'dropout': 0.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch [30/30], Avg Training Loss: 0.9704\n",
            "  Validation AUC: 0.7334\n",
            "  *** New Best Model Found (AUC: 0.7334) ***\n",
            "\n",
            "--- Tuning Run 2/3 ---\n",
            "Params: {'lr': 0.001, 'batch_size': 1024, 'hidden_1': 512, 'hidden_2': 256, 'hidden_3': 128, 'dropout': 0.5}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch [30/30], Avg Training Loss: 0.9631\n",
            "  Validation AUC: 0.7315\n",
            "\n",
            "--- Tuning Run 3/3 ---\n",
            "Params: {'lr': 0.0001, 'batch_size': 2048, 'hidden_1': 256, 'hidden_2': 128, 'hidden_3': 0, 'dropout': 0.4}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch [30/30], Avg Training Loss: 0.9819\n",
            "  Validation AUC: 0.7322\n",
            "\n",
            "--- Hyperparameter Tuning Complete ---\n",
            "Best Validation AUC: 0.7334\n",
            "Best Parameters: {'lr': 0.0005, 'batch_size': 2048, 'hidden_1': 256, 'hidden_2': 128, 'hidden_3': 0, 'dropout': 0.4}\n",
            "\n",
            "Loading best model for final test set evaluation...\n",
            "Saving best model weights to /content/drive/MyDrive/shodhAI/dl_model_weights.pth...\n",
            "Model saved successfully.\n",
            "\n",
            "--- Starting Final Model Evaluation on TEST SET ---\n",
            "\n",
            "--- Test Set Performance (Task 2) ---\n",
            "AUC (Area Under the ROC Curve): 0.7311\n",
            "-----------------------------------------\n",
            "Optimal Threshold (for max F1): 0.5160\n",
            "Metrics at optimal threshold:\n",
            "  Best F1-Score:                  0.4470\n",
            "  Precision (at best F1):         0.3410\n",
            "  Recall (at best F1):            0.6485\n",
            "\n",
            "--- Task 2 Complete ---\n"
          ]
        }
      ]
    }
  ]
}